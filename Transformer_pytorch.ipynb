{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-29T09:45:33.991248Z",
     "start_time": "2024-10-29T09:45:31.616422400Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_data(device='cpu'):\n",
    "    # 加载 IMDB 数据集\n",
    "    (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "    \n",
    "    # 统一长度，不足的填充 0\n",
    "    max_len = 200\n",
    "    train_data = [torch.tensor(seq)[:max_len] for seq in train_data]\n",
    "    test_data = [torch.tensor(seq)[:max_len] for seq in test_data]\n",
    "    \n",
    "    # 填充数据\n",
    "    train_data = pad_sequence(train_data, batch_first=True)\n",
    "    test_data = pad_sequence(test_data, batch_first=True)\n",
    "    \n",
    "    # 转换为 pytorch tensor\n",
    "    train_labels = torch.tensor(train_labels, dtype=torch.float32, device=device)\n",
    "    test_labels = torch.tensor(test_labels, dtype=torch.float32, device=device)\n",
    "    train_data = torch.tensor(train_data, dtype=torch.long, device=device)\n",
    "    test_data = torch.tensor(test_data, dtype=torch.long, device=device)\n",
    "    \n",
    "    # 查看数据集大小\n",
    "    print(f'训练集大小: {len(train_data)}')\n",
    "    print(f'测试集大小: {len(test_data)}')\n",
    "    print(\"train labels shape: \", train_labels.shape)\n",
    "    print(\"test labels shape: \", test_labels.shape)\n",
    "    print(\"train data shape: \", train_data.shape)\n",
    "    print(\"test data shape: \", test_data.shape)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T09:45:34.021102300Z",
     "start_time": "2024-10-29T09:45:33.992074700Z"
    }
   },
   "id": "937ef8d44979ad91"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 25000\n",
      "测试集大小: 25000\n",
      "train labels shape:  torch.Size([25000])\n",
      "test labels shape:  torch.Size([25000])\n",
      "train data shape:  torch.Size([25000, 200])\n",
      "test data shape:  torch.Size([25000, 200])\n",
      "tensor([   1,   14,   22,   16,   43,  530,  973, 1622, 1385,   65,  458, 4468,\n",
      "          66, 3941,    4,  173,   36,  256,    5,   25,  100,   43,  838,  112,\n",
      "          50,  670,    2,    9,   35,  480,  284,    5,  150,    4,  172,  112,\n",
      "         167,    2,  336,  385,   39,    4,  172, 4536, 1111,   17,  546,   38,\n",
      "          13,  447,    4,  192,   50,   16,    6,  147, 2025,   19,   14,   22,\n",
      "           4, 1920, 4613,  469,    4,   22,   71,   87,   12,   16,   43,  530,\n",
      "          38,   76,   15,   13, 1247,    4,   22,   17,  515,   17,   12,   16,\n",
      "         626,   18,    2,    5,   62,  386,   12,    8,  316,    8,  106,    5,\n",
      "           4, 2223, 5244,   16,  480,   66, 3785,   33,    4,  130,   12,   16,\n",
      "          38,  619,    5,   25,  124,   51,   36,  135,   48,   25, 1415,   33,\n",
      "           6,   22,   12,  215,   28,   77,   52,    5,   14,  407,   16,   82,\n",
      "           2,    8,    4,  107,  117, 5952,   15,  256,    4,    2,    7, 3766,\n",
      "           5,  723,   36,   71,   43,  530,  476,   26,  400,  317,   46,    7,\n",
      "           4,    2, 1029,   13,  104,   88,    4,  381,   15,  297,   98,   32,\n",
      "        2071,   56,   26,  141,    6,  194, 7486,   18,    4,  226,   22,   21,\n",
      "         134,  476,   26,  480,    5,  144,   30, 5535,   18,   51,   36,   28,\n",
      "         224,   92,   25,  104,    4,  226,   65,   16], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_data, train_labels, test_data, test_labels = load_data(device=device)\n",
    "print(train_data[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T09:45:36.706026900Z",
     "start_time": "2024-10-29T09:45:34.016082Z"
    }
   },
   "id": "f7e387081adb50c4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=200):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.encoding = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        self.encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        self.encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.encoding = self.encoding.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.encoding[:, :seq_len, :].to(x.device)\n",
    "\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_heads, hidden_dim, num_layers, output_dim, dropout=0.1, max_len=200):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_encoding = PositionalEncoding(embed_size, max_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(embed_size, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        encoded = self.positional_encoding(embedded)  # 加入位置编码\n",
    "        transformer_out = self.transformer(encoded)\n",
    "        out = self.fc(self.dropout(transformer_out.mean(dim=1)))  # 平均池化取每个序列的特征\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T09:45:36.713023900Z",
     "start_time": "2024-10-29T09:45:36.710020400Z"
    }
   },
   "id": "b454c214f38155e9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "class DataLoaderX(DataLoader):\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__(), max_prefetch=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T09:45:36.719024900Z",
     "start_time": "2024-10-29T09:45:36.714022900Z"
    }
   },
   "id": "e253efbe76b640d7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, criterion, optimizer, num_epochs=5, batch_size=128):\n",
    "    # 创建数据集和数据加载器\n",
    "    dataset = IMDBDataset(train_data, train_labels)\n",
    "    train_loader = DataLoaderX(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            correct += (torch.round(torch.sigmoid(outputs)).squeeze() == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # 需要调整标签形状\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {correct/total:.4f}')\n",
    "\n",
    "def evaluate_model(model, test_data, test_labels, batch_size=32):\n",
    "    dataset = IMDBDataset(test_data, test_labels)\n",
    "    test_loader = DataLoaderX(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            predictions = torch.round(torch.sigmoid(outputs))\n",
    "            correct += (predictions.squeeze() == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T09:45:36.723993200Z",
     "start_time": "2024-10-29T09:45:36.720025300Z"
    }
   },
   "id": "d60e1463e54b052d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} device')\n",
    "\n",
    "# 设置超参数\n",
    "vocab_size = 10000\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "n_layers = 3\n",
    "dropout = 0.2\n",
    "num_epochs = 30\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "max_len = 200"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T09:45:37.041053900Z",
     "start_time": "2024-10-29T09:45:37.036047800Z"
    }
   },
   "id": "3eabd3230938a869"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6547, Accuracy: 0.5701\n",
      "Epoch [2/100], Loss: 0.5133, Accuracy: 0.6376\n",
      "Epoch [3/100], Loss: 0.4719, Accuracy: 0.6775\n",
      "Epoch [4/100], Loss: 0.5312, Accuracy: 0.7039\n",
      "Epoch [5/100], Loss: 0.4836, Accuracy: 0.7230\n",
      "Epoch [6/100], Loss: 0.4194, Accuracy: 0.7378\n",
      "Epoch [7/100], Loss: 0.4120, Accuracy: 0.7492\n",
      "Epoch [8/100], Loss: 0.3400, Accuracy: 0.7588\n",
      "Epoch [9/100], Loss: 0.3721, Accuracy: 0.7671\n",
      "Epoch [10/100], Loss: 0.3356, Accuracy: 0.7744\n",
      "Epoch [11/100], Loss: 0.3562, Accuracy: 0.7810\n",
      "Epoch [12/100], Loss: 0.4042, Accuracy: 0.7870\n",
      "Epoch [13/100], Loss: 0.3002, Accuracy: 0.7923\n",
      "Epoch [14/100], Loss: 0.2824, Accuracy: 0.7975\n",
      "Epoch [15/100], Loss: 0.3203, Accuracy: 0.8024\n",
      "Epoch [16/100], Loss: 0.2772, Accuracy: 0.8073\n",
      "Epoch [17/100], Loss: 0.2749, Accuracy: 0.8119\n",
      "Epoch [18/100], Loss: 0.3094, Accuracy: 0.8163\n",
      "Epoch [19/100], Loss: 0.2346, Accuracy: 0.8205\n",
      "Epoch [20/100], Loss: 0.1999, Accuracy: 0.8245\n",
      "Epoch [21/100], Loss: 0.2210, Accuracy: 0.8284\n",
      "Epoch [22/100], Loss: 0.2238, Accuracy: 0.8322\n",
      "Epoch [23/100], Loss: 0.1865, Accuracy: 0.8360\n",
      "Epoch [24/100], Loss: 0.2313, Accuracy: 0.8393\n",
      "Epoch [25/100], Loss: 0.2005, Accuracy: 0.8429\n",
      "Epoch [26/100], Loss: 0.1309, Accuracy: 0.8463\n",
      "Epoch [27/100], Loss: 0.1634, Accuracy: 0.8497\n",
      "Epoch [28/100], Loss: 0.1276, Accuracy: 0.8528\n",
      "Epoch [29/100], Loss: 0.2292, Accuracy: 0.8559\n",
      "Epoch [30/100], Loss: 0.1074, Accuracy: 0.8589\n",
      "Epoch [31/100], Loss: 0.1078, Accuracy: 0.8620\n",
      "Epoch [32/100], Loss: 0.0823, Accuracy: 0.8650\n",
      "Epoch [33/100], Loss: 0.1154, Accuracy: 0.8679\n",
      "Epoch [34/100], Loss: 0.1489, Accuracy: 0.8706\n",
      "Epoch [35/100], Loss: 0.1220, Accuracy: 0.8733\n",
      "Epoch [36/100], Loss: 0.0648, Accuracy: 0.8759\n",
      "Epoch [37/100], Loss: 0.0712, Accuracy: 0.8786\n",
      "Epoch [38/100], Loss: 0.1034, Accuracy: 0.8812\n",
      "Epoch [39/100], Loss: 0.0834, Accuracy: 0.8836\n",
      "Epoch [40/100], Loss: 0.0854, Accuracy: 0.8859\n",
      "Epoch [41/100], Loss: 0.0603, Accuracy: 0.8882\n",
      "Epoch [42/100], Loss: 0.0683, Accuracy: 0.8904\n",
      "Epoch [43/100], Loss: 0.0592, Accuracy: 0.8926\n",
      "Epoch [44/100], Loss: 0.0428, Accuracy: 0.8947\n",
      "Epoch [45/100], Loss: 0.0285, Accuracy: 0.8967\n",
      "Epoch [46/100], Loss: 0.0390, Accuracy: 0.8986\n",
      "Epoch [47/100], Loss: 0.0278, Accuracy: 0.9004\n",
      "Epoch [48/100], Loss: 0.0226, Accuracy: 0.9022\n",
      "Epoch [49/100], Loss: 0.0450, Accuracy: 0.9039\n",
      "Epoch [50/100], Loss: 0.0409, Accuracy: 0.9055\n",
      "Epoch [51/100], Loss: 0.0123, Accuracy: 0.9072\n",
      "Epoch [52/100], Loss: 0.0557, Accuracy: 0.9088\n",
      "Epoch [53/100], Loss: 0.0333, Accuracy: 0.9103\n",
      "Epoch [54/100], Loss: 0.0360, Accuracy: 0.9118\n",
      "Epoch [55/100], Loss: 0.0201, Accuracy: 0.9133\n",
      "Epoch [56/100], Loss: 0.0357, Accuracy: 0.9147\n",
      "Epoch [57/100], Loss: 0.0232, Accuracy: 0.9161\n",
      "Epoch [58/100], Loss: 0.0710, Accuracy: 0.9175\n",
      "Epoch [59/100], Loss: 0.0357, Accuracy: 0.9187\n",
      "Epoch [60/100], Loss: 0.0346, Accuracy: 0.9199\n",
      "Epoch [61/100], Loss: 0.0351, Accuracy: 0.9211\n",
      "Epoch [62/100], Loss: 0.0371, Accuracy: 0.9222\n",
      "Epoch [63/100], Loss: 0.0431, Accuracy: 0.9233\n",
      "Epoch [64/100], Loss: 0.1114, Accuracy: 0.9243\n",
      "Epoch [65/100], Loss: 0.0386, Accuracy: 0.9253\n",
      "Epoch [66/100], Loss: 0.0238, Accuracy: 0.9264\n",
      "Epoch [67/100], Loss: 0.0232, Accuracy: 0.9274\n",
      "Epoch [68/100], Loss: 0.0228, Accuracy: 0.9284\n",
      "Epoch [69/100], Loss: 0.0050, Accuracy: 0.9293\n",
      "Epoch [70/100], Loss: 0.0046, Accuracy: 0.9303\n",
      "Epoch [71/100], Loss: 0.0044, Accuracy: 0.9312\n",
      "Epoch [72/100], Loss: 0.0066, Accuracy: 0.9321\n",
      "Epoch [73/100], Loss: 0.0071, Accuracy: 0.9330\n",
      "Epoch [74/100], Loss: 0.0122, Accuracy: 0.9338\n",
      "Epoch [75/100], Loss: 0.0050, Accuracy: 0.9346\n",
      "Epoch [76/100], Loss: 0.0454, Accuracy: 0.9353\n",
      "Epoch [77/100], Loss: 0.0629, Accuracy: 0.9360\n",
      "Epoch [78/100], Loss: 0.0063, Accuracy: 0.9367\n",
      "Epoch [79/100], Loss: 0.0097, Accuracy: 0.9374\n",
      "Epoch [80/100], Loss: 0.0319, Accuracy: 0.9381\n",
      "Epoch [81/100], Loss: 0.0057, Accuracy: 0.9389\n",
      "Epoch [82/100], Loss: 0.0094, Accuracy: 0.9396\n",
      "Epoch [83/100], Loss: 0.0076, Accuracy: 0.9403\n",
      "Epoch [84/100], Loss: 0.0095, Accuracy: 0.9410\n",
      "Epoch [85/100], Loss: 0.0036, Accuracy: 0.9416\n",
      "Epoch [86/100], Loss: 0.0027, Accuracy: 0.9423\n",
      "Epoch [87/100], Loss: 0.0032, Accuracy: 0.9429\n",
      "Epoch [88/100], Loss: 0.0093, Accuracy: 0.9435\n",
      "Epoch [89/100], Loss: 0.0545, Accuracy: 0.9441\n",
      "Epoch [90/100], Loss: 0.0314, Accuracy: 0.9446\n",
      "Epoch [91/100], Loss: 0.0021, Accuracy: 0.9452\n",
      "Epoch [92/100], Loss: 0.0279, Accuracy: 0.9457\n",
      "Epoch [93/100], Loss: 0.0238, Accuracy: 0.9462\n",
      "Epoch [94/100], Loss: 0.0174, Accuracy: 0.9468\n",
      "Epoch [95/100], Loss: 0.0071, Accuracy: 0.9473\n",
      "Epoch [96/100], Loss: 0.0236, Accuracy: 0.9478\n",
      "Epoch [97/100], Loss: 0.0179, Accuracy: 0.9483\n",
      "Epoch [98/100], Loss: 0.0218, Accuracy: 0.9488\n",
      "Epoch [99/100], Loss: 0.0378, Accuracy: 0.9493\n",
      "Epoch [100/100], Loss: 0.0090, Accuracy: 0.9497\n",
      "Accuracy: 0.7999\n"
     ]
    }
   ],
   "source": [
    "# Transformer 模型训练与评估\n",
    "transformer_model = TransformerModel(vocab_size, embedding_dim, 8, hidden_dim, n_layers, output_dim, dropout, max_len=200)\n",
    "transformer_model = transformer_model.to(device)\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train_model(transformer_model, train_data, train_labels, criterion, optimizer, num_epochs=100, batch_size=batch_size)\n",
    "evaluate_model(transformer_model, test_data, test_labels, batch_size)\n",
    "torch.save(transformer_model.state_dict(), 'data' + os.sep + 'transformer_model.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T09:42:51.540508400Z",
     "start_time": "2024-10-29T09:38:19.912036700Z"
    }
   },
   "id": "b47fa9b3c2644f22"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample sentence: \n",
      "[START] please give this one a miss br br [OOV] [OOV] and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite [OOV] so all you madison fans give this a miss [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "def index2word(sentence_index):\n",
    "    start_char = 1\n",
    "    oov_char = 2\n",
    "    index_from = 3\n",
    "    \n",
    "    word_index = imdb.get_word_index()\n",
    "    inverted_word_index = dict(\n",
    "        (i + index_from, word) for (word, i) in word_index.items()\n",
    "    )\n",
    "    \n",
    "    inverted_word_index[start_char] = \"[START]\"\n",
    "    inverted_word_index[oov_char] = \"[OOV]\"\n",
    "    inverted_word_index[0] = \"[PAD]\"\n",
    "    \n",
    "    decoded_sequence = \" \".join(inverted_word_index[i] for i in sentence_index)\n",
    "    return decoded_sequence\n",
    "\n",
    "def word2index(sentence_word):\n",
    "    start_char = 1\n",
    "    oov_char = 2\n",
    "    index_from = 3\n",
    "    \n",
    "    word_index = imdb.get_word_index()\n",
    "    inverted_word_index = dict(\n",
    "        (word, i + index_from) for (word, i) in word_index.items()\n",
    "    )\n",
    "    inverted_word_index[\"[START]\"] = start_char\n",
    "    inverted_word_index[\"[OOV]\"] = oov_char\n",
    "    inverted_word_index[\"[PAD]\"] = 0\n",
    "    \n",
    "    sentence_index = [inverted_word_index.get(word, 0) for word in sentence_word]\n",
    "    return sentence_index\n",
    "\n",
    "# 使用句子测试\n",
    "def predict_sentiment(sentence, model, vocab_size=200, max_len=200, device='cpu', other_data=None):\n",
    "    # 预处理句子\n",
    "    sentence = sentence.lower().split(\" \")\n",
    "    sentence = word2index(sentence)\n",
    "    sentence = torch.tensor(sentence).to(device)\n",
    "    # 使用\"[PAD]\"填充\n",
    "    if len(sentence) < max_len:\n",
    "        sentence = torch.cat([sentence, torch.zeros(max_len-len(sentence), dtype=torch.long, device=device)])\n",
    "    else:\n",
    "        sentence = sentence[:max_len]\n",
    "    sentence = pad_sequence([sentence], batch_first=True)\n",
    "    # 拼接train_data\n",
    "    sentence = torch.cat([other_data, sentence], dim=0)\n",
    "    \n",
    "    # 预测\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(sentence)\n",
    "        prediction = torch.round(torch.sigmoid(output))\n",
    "    return prediction[-1].item()\n",
    "\n",
    "print(\"Sample sentence: \")\n",
    "print(index2word(test_data[0].cpu().numpy()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T09:58:20.779221700Z",
     "start_time": "2024-10-29T09:58:20.736223500Z"
    }
   },
   "id": "bd66b9b4de5dd78f"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: [START] this movie is great I love it It is the best movie ever [OOV], Prediction: Positive\n",
      "Sentence: [START] It is terrible [OOV], Prediction: Negative\n",
      "Sentence: [START] I love this movie [OOV], Prediction: Positive\n",
      "Sentence: [START] It is not good enough [OOV], Prediction: Negative\n",
      "Sentence: [START] the director is a big fool [OOV], Prediction: Negative\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transformer_model = TransformerModel(vocab_size, embedding_dim, 8, hidden_dim, n_layers, output_dim, dropout, max_len=200)\n",
    "transformer_model = transformer_model.to(device)\n",
    "transformer_model.load_state_dict(torch.load('data' + os.sep + 'transformer_model.pth', map_location=device))\n",
    "# 选择一部分数据作为其他数据, 避免单个样本\n",
    "other_data = train_data[:255]\n",
    "\n",
    "sentence = '[START] this movie is great I love it It is the best movie ever [OOV]'\n",
    "prediction = predict_sentiment(sentence, transformer_model, device=device, other_data=other_data)\n",
    "print(f'Sentence: {sentence}, Prediction: {\"Positive\" if prediction == 1 else \"Negative\"}')\n",
    "\n",
    "sentence = '[START] It is terrible [OOV]'\n",
    "prediction = predict_sentiment(sentence, transformer_model, device=device, other_data=other_data)\n",
    "print(f'Sentence: {sentence}, Prediction: {\"Positive\" if prediction == 1 else \"Negative\"}')\n",
    "\n",
    "sentence = '[START] I love this movie [OOV]'\n",
    "prediction = predict_sentiment(sentence, transformer_model, device=device, other_data=other_data)\n",
    "print(f'Sentence: {sentence}, Prediction: {\"Positive\" if prediction == 1 else \"Negative\"}')\n",
    "\n",
    "sentence = '[START] It is not good enough [OOV]'\n",
    "prediction = predict_sentiment(sentence, transformer_model, device=device, other_data=other_data)\n",
    "print(f'Sentence: {sentence}, Prediction: {\"Positive\" if prediction == 1 else \"Negative\"}')\n",
    "\n",
    "sentence = '[START] the director is a big fool [OOV]'\n",
    "prediction = predict_sentiment(sentence, transformer_model, device=device, other_data=other_data)\n",
    "print(f'Sentence: {sentence}, Prediction: {\"Positive\" if prediction == 1 else \"Negative\"}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-29T10:00:40.839872400Z",
     "start_time": "2024-10-29T10:00:40.097827800Z"
    }
   },
   "id": "1a79c0c6a6dc6d86"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "99317d68f3a5abe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
