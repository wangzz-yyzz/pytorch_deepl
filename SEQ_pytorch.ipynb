{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-10-29T11:08:00.123240Z",
     "end_time": "2024-10-29T11:08:08.447086Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # 加载 IMDB 数据集\n",
    "    (train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=200)\n",
    "\n",
    "    # 查看数据集大小\n",
    "    print(f'训练集大小: {len(train_data)}')\n",
    "    print(f'测试集大小: {len(test_data)}')\n",
    "    print(\"train labels shape: \", train_labels.shape)\n",
    "    print(\"test labels shape: \", test_labels.shape)\n",
    "\n",
    "    # 填充数据\n",
    "    max_len = 50\n",
    "    train_data = pad_sequence([torch.tensor(seq)[:max_len] for seq in train_data], batch_first=True)\n",
    "    test_data = pad_sequence([torch.tensor(seq)[:max_len] for seq in test_data], batch_first=True)\n",
    "    print(\"train data shape: \", train_data.shape)\n",
    "    print(\"test data shape: \", test_data.shape)\n",
    "\n",
    "    # 转换为 pytorch tensor\n",
    "    train_labels = torch.tensor(train_labels, dtype=torch.float32)\n",
    "    test_labels = torch.tensor(test_labels, dtype=torch.float32)\n",
    "    train_data = torch.tensor(train_data, dtype=torch.long)\n",
    "    test_data = torch.tensor(test_data, dtype=torch.long)\n",
    "    return train_data, train_labels, test_data, test_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-29T11:08:10.352429Z",
     "end_time": "2024-10-29T11:08:10.378328Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 25000\n",
      "测试集大小: 25000\n",
      "train labels shape:  (25000,)\n",
      "test labels shape:  (25000,)\n",
      "train data shape:  torch.Size([25000, 50])\n",
      "test data shape:  torch.Size([25000, 50])\n"
     ]
    }
   ],
   "source": [
    "train_data, train_labels, test_data, test_labels = load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-29T11:08:10.961275Z",
     "end_time": "2024-10-29T11:08:14.709246Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        out = self.dropout(lstm_out[:, -1, :])  # 取最后一层输出\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-29T11:08:14.811827Z",
     "end_time": "2024-10-29T11:08:14.822832Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        rnn_out, _ = self.rnn(x)\n",
    "        out = self.dropout(rnn_out[:, -1, :])  # 取最后一层输出\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-29T11:08:15.651696Z",
     "end_time": "2024-10-29T11:08:15.663090Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim, n_heads, num_layers):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(dim_feedforward=embedding_dim, d_model=embedding_dim, nhead=n_heads),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)  # 转换为 (seq_len, batch_size, embedding_dim)\n",
    "        transformer_out = self.transformer_encoder(x)\n",
    "        out = transformer_out[-1, :, :]  # 取最后一个时间步的输出\n",
    "        out = self.fc(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-29T11:08:16.206318Z",
     "end_time": "2024-10-29T11:08:16.232873Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "class DataLoaderX(DataLoader):\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__(), max_prefetch=8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-29T11:08:16.809400Z",
     "end_time": "2024-10-29T11:08:16.829744Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def train_model(model, train_data, train_labels, criterion, optimizer, num_epochs=5, batch_size=128):\n",
    "    # 创建数据集和数据加载器\n",
    "    dataset = IMDBDataset(train_data, train_labels)\n",
    "    train_loader = DataLoaderX(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            correct += (torch.round(torch.sigmoid(outputs)).squeeze() == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1))  # 需要调整标签形状\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Accuracy: {correct/total:.4f}')\n",
    "\n",
    "def evaluate_model(model, test_data, test_labels, batch_size=32):\n",
    "    dataset = IMDBDataset(test_data, test_labels)\n",
    "    test_loader = DataLoaderX(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            predictions = torch.round(torch.sigmoid(outputs))\n",
    "            correct += (predictions.squeeze() == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy: {accuracy:.4f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-29T11:08:17.767025Z",
     "end_time": "2024-10-29T11:08:17.778055Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "训练集大小: 25000\n",
      "测试集大小: 25000\n",
      "train labels shape:  (25000,)\n",
      "test labels shape:  (25000,)\n",
      "train data shape:  torch.Size([25000, 50])\n",
      "test data shape:  torch.Size([25000, 50])\n",
      "Epoch [1/30], Loss: 0.6620, Accuracy: 0.5381\n",
      "Epoch [2/30], Loss: 0.6728, Accuracy: 0.5808\n",
      "Epoch [3/30], Loss: 0.6614, Accuracy: 0.6043\n",
      "Epoch [4/30], Loss: 0.5909, Accuracy: 0.6202\n",
      "Epoch [5/30], Loss: 0.5619, Accuracy: 0.6316\n",
      "Epoch [6/30], Loss: 0.5911, Accuracy: 0.6397\n",
      "Epoch [7/30], Loss: 0.5427, Accuracy: 0.6467\n",
      "Epoch [8/30], Loss: 0.5204, Accuracy: 0.6533\n",
      "Epoch [9/30], Loss: 0.5500, Accuracy: 0.6592\n",
      "Epoch [10/30], Loss: 0.5961, Accuracy: 0.6643\n",
      "Epoch [11/30], Loss: 0.4955, Accuracy: 0.6696\n",
      "Epoch [12/30], Loss: 0.5633, Accuracy: 0.6749\n",
      "Epoch [13/30], Loss: 0.6396, Accuracy: 0.6801\n",
      "Epoch [14/30], Loss: 0.4739, Accuracy: 0.6856\n",
      "Epoch [15/30], Loss: 0.3970, Accuracy: 0.6907\n",
      "Epoch [16/30], Loss: 0.4682, Accuracy: 0.6962\n",
      "Epoch [17/30], Loss: 0.4280, Accuracy: 0.7016\n",
      "Epoch [18/30], Loss: 0.4327, Accuracy: 0.7073\n",
      "Epoch [19/30], Loss: 0.4709, Accuracy: 0.7131\n",
      "Epoch [20/30], Loss: 0.3807, Accuracy: 0.7190\n",
      "Epoch [21/30], Loss: 0.3650, Accuracy: 0.7247\n",
      "Epoch [22/30], Loss: 0.3750, Accuracy: 0.7307\n",
      "Epoch [23/30], Loss: 0.4135, Accuracy: 0.7364\n",
      "Epoch [24/30], Loss: 0.3523, Accuracy: 0.7421\n",
      "Epoch [25/30], Loss: 0.3233, Accuracy: 0.7478\n",
      "Epoch [26/30], Loss: 0.3017, Accuracy: 0.7533\n",
      "Epoch [27/30], Loss: 0.3518, Accuracy: 0.7587\n",
      "Epoch [28/30], Loss: 0.1910, Accuracy: 0.7642\n",
      "Epoch [29/30], Loss: 0.2286, Accuracy: 0.7695\n",
      "Epoch [30/30], Loss: 0.2233, Accuracy: 0.7744\n",
      "Accuracy: 0.6469\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device} device')\n",
    "# 加载数据\n",
    "train_data, train_labels, test_data, test_labels = load_data()\n",
    "train_data, train_labels, test_data, test_labels = train_data.to(device), train_labels.to(device), test_data.to(device), test_labels.to(device)\n",
    "\n",
    "# 设置超参数\n",
    "vocab_size = 200\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "output_dim = 1\n",
    "n_layers = 3\n",
    "dropout = 0.5\n",
    "num_epochs = 30\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "\n",
    "# LSTM 模型训练与评估\n",
    "lstm_model = LSTMModel(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "lstm_model = lstm_model.to(device)\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train_model(lstm_model, train_data, train_labels, criterion, optimizer, num_epochs, batch_size)\n",
    "evaluate_model(lstm_model, test_data, test_labels, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-29T11:08:39.289119Z",
     "end_time": "2024-10-29T11:10:15.915946Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 25000\n",
      "测试集大小: 25000\n",
      "train labels shape:  (25000,)\n",
      "test labels shape:  (25000,)\n",
      "train data shape:  torch.Size([25000, 50])\n",
      "test data shape:  torch.Size([25000, 50])\n",
      "Epoch [1/30], Loss: 0.6862, Accuracy: 0.5024\n",
      "Epoch [2/30], Loss: 0.6530, Accuracy: 0.5142\n",
      "Epoch [3/30], Loss: 0.7320, Accuracy: 0.5278\n",
      "Epoch [4/30], Loss: 0.6840, Accuracy: 0.5340\n",
      "Epoch [5/30], Loss: 0.7141, Accuracy: 0.5361\n",
      "Epoch [6/30], Loss: 0.6767, Accuracy: 0.5381\n",
      "Epoch [7/30], Loss: 0.6228, Accuracy: 0.5423\n",
      "Epoch [8/30], Loss: 0.7272, Accuracy: 0.5434\n",
      "Epoch [9/30], Loss: 0.6129, Accuracy: 0.5472\n",
      "Epoch [10/30], Loss: 0.7102, Accuracy: 0.5472\n",
      "Epoch [11/30], Loss: 0.7158, Accuracy: 0.5439\n",
      "Epoch [12/30], Loss: 0.7000, Accuracy: 0.5424\n",
      "Epoch [13/30], Loss: 0.6916, Accuracy: 0.5420\n",
      "Epoch [14/30], Loss: 0.6678, Accuracy: 0.5420\n",
      "Epoch [15/30], Loss: 0.6760, Accuracy: 0.5420\n",
      "Epoch [16/30], Loss: 0.7196, Accuracy: 0.5415\n",
      "Epoch [17/30], Loss: 0.6909, Accuracy: 0.5418\n",
      "Epoch [18/30], Loss: 0.6839, Accuracy: 0.5419\n",
      "Epoch [19/30], Loss: 0.6864, Accuracy: 0.5426\n",
      "Epoch [20/30], Loss: 0.7070, Accuracy: 0.5439\n",
      "Epoch [21/30], Loss: 0.7264, Accuracy: 0.5430\n",
      "Epoch [22/30], Loss: 0.6669, Accuracy: 0.5428\n",
      "Epoch [23/30], Loss: 0.6629, Accuracy: 0.5434\n",
      "Epoch [24/30], Loss: 0.6730, Accuracy: 0.5439\n",
      "Epoch [25/30], Loss: 0.7042, Accuracy: 0.5436\n",
      "Epoch [26/30], Loss: 0.7031, Accuracy: 0.5435\n",
      "Epoch [27/30], Loss: 0.7092, Accuracy: 0.5430\n",
      "Epoch [28/30], Loss: 0.6884, Accuracy: 0.5427\n",
      "Epoch [29/30], Loss: 0.7041, Accuracy: 0.5429\n",
      "Epoch [30/30], Loss: 0.6977, Accuracy: 0.5436\n",
      "Accuracy: 0.5318\n"
     ]
    }
   ],
   "source": [
    "# RNN 模型训练与评估\n",
    "train_data, train_labels, test_data, test_labels = load_data()\n",
    "train_data, train_labels, test_data, test_labels = train_data.to(device), train_labels.to(device), test_data.to(device), test_labels.to(device)\n",
    "rnn_model = RNNModel(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout)\n",
    "rnn_model = rnn_model.to(device)\n",
    "optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train_model(rnn_model, train_data, train_labels, criterion, optimizer, num_epochs, batch_size)\n",
    "evaluate_model(rnn_model, test_data, test_labels, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-29T01:54:33.707671Z",
     "end_time": "2024-10-29T01:54:55.092267Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 25000\n",
      "测试集大小: 25000\n",
      "train labels shape:  (25000,)\n",
      "test labels shape:  (25000,)\n",
      "train data shape:  torch.Size([25000, 50])\n",
      "test data shape:  torch.Size([25000, 50])\n",
      "Epoch [1/30], Loss: 0.6736, Accuracy: 0.5949\n",
      "Epoch [2/30], Loss: 0.6139, Accuracy: 0.6226\n",
      "Epoch [3/30], Loss: 0.5651, Accuracy: 0.6357\n",
      "Epoch [4/30], Loss: 0.6579, Accuracy: 0.6459\n",
      "Epoch [5/30], Loss: 0.6625, Accuracy: 0.6541\n",
      "Epoch [6/30], Loss: 0.8026, Accuracy: 0.6608\n",
      "Epoch [7/30], Loss: 0.7271, Accuracy: 0.6672\n",
      "Epoch [8/30], Loss: 0.6410, Accuracy: 0.6725\n",
      "Epoch [9/30], Loss: 0.5638, Accuracy: 0.6779\n",
      "Epoch [10/30], Loss: 0.4935, Accuracy: 0.6824\n",
      "Epoch [11/30], Loss: 0.3882, Accuracy: 0.6869\n",
      "Epoch [12/30], Loss: 0.7272, Accuracy: 0.6909\n",
      "Epoch [13/30], Loss: 0.2741, Accuracy: 0.6949\n",
      "Epoch [14/30], Loss: 0.6343, Accuracy: 0.6985\n",
      "Epoch [15/30], Loss: 0.5324, Accuracy: 0.7019\n",
      "Epoch [16/30], Loss: 0.5798, Accuracy: 0.7048\n",
      "Epoch [17/30], Loss: 0.9732, Accuracy: 0.7076\n",
      "Epoch [18/30], Loss: 0.4634, Accuracy: 0.7104\n",
      "Epoch [19/30], Loss: 0.4727, Accuracy: 0.7131\n",
      "Epoch [20/30], Loss: 0.3501, Accuracy: 0.7156\n",
      "Epoch [21/30], Loss: 0.6035, Accuracy: 0.7180\n",
      "Epoch [22/30], Loss: 0.4868, Accuracy: 0.7202\n",
      "Epoch [23/30], Loss: 0.3132, Accuracy: 0.7223\n",
      "Epoch [24/30], Loss: 0.8719, Accuracy: 0.7245\n",
      "Epoch [25/30], Loss: 0.3049, Accuracy: 0.7264\n",
      "Epoch [26/30], Loss: 0.2193, Accuracy: 0.7284\n",
      "Epoch [27/30], Loss: 0.5110, Accuracy: 0.7302\n",
      "Epoch [28/30], Loss: 0.3384, Accuracy: 0.7321\n",
      "Epoch [29/30], Loss: 0.4499, Accuracy: 0.7338\n",
      "Epoch [30/30], Loss: 0.5087, Accuracy: 0.7356\n",
      "Accuracy: 0.6213\n"
     ]
    }
   ],
   "source": [
    "# Transformer 模型训练与评估\n",
    "train_data, train_labels, test_data, test_labels = load_data()\n",
    "train_data, train_labels, test_data, test_labels = train_data.to(device), train_labels.to(device), test_data.to(device), test_labels.to(device)\n",
    "transformer_model = TransformerModel(vocab_size, embedding_dim, output_dim, n_heads=16, num_layers=n_layers)\n",
    "transformer_model = transformer_model.to(device)\n",
    "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train_model(transformer_model, train_data, train_labels, criterion, optimizer, num_epochs, 16)\n",
    "evaluate_model(transformer_model, test_data, test_labels, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-10-29T01:56:33.700222Z",
     "end_time": "2024-10-29T01:59:11.920136Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
